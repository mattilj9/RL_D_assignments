\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\HyPL@Entry{0<</S/D>>}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Training performance using a constant value of $\epsilon = 0.2$.}}{1}{figure.1}\protected@file@percent }
\newlabel{fig:fig1}{{1}{1}{Training performance using a constant value of $\epsilon = 0.2$}{figure.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Training performance using the GLIE formula for $\epsilon $.}}{2}{figure.2}\protected@file@percent }
\newlabel{fig:fig2}{{2}{2}{Training performance using the GLIE formula for $\epsilon $}{figure.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Heatmap of the value function in terms of $x$ and $\theta $.}}{3}{figure.3}\protected@file@percent }
\newlabel{fig:fig3}{{3}{3}{Heatmap of the value function in terms of $x$ and $\theta $}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Training performance using $\epsilon $ with zero value (i.e. greedy policy) and keeping the intial estimates of the Q function at 0.}}{4}{figure.4}\protected@file@percent }
\newlabel{fig:fig4}{{4}{4}{Training performance using $\epsilon $ with zero value (i.e. greedy policy) and keeping the intial estimates of the Q function at 0}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Training performance using $\epsilon $ with zero value (i.e. greedy policy) and setting the initial estimates of the Q function to 50 for all states and actions.}}{5}{figure.5}\protected@file@percent }
\newlabel{fig:fig5}{{5}{5}{Training performance using $\epsilon $ with zero value (i.e. greedy policy) and setting the initial estimates of the Q function to 50 for all states and actions}{figure.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Training performance of the lunar lander using $\epsilon $ with GLIE.}}{6}{figure.6}\protected@file@percent }
\newlabel{fig:fig6}{{6}{6}{Training performance of the lunar lander using $\epsilon $ with GLIE}{figure.6}{}}
\bibstyle{ieeetr}
\bibdata{template}
